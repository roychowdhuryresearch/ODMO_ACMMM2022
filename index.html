<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Action-conditioned On-demand Motion Generation</title>
    <link href="./css/bootstrap.min.css" rel="stylesheet">
  </head>
  <body>
    <div id="page_container">
      <header>
        <div class="jumbotron" >
          <div class="container">
            <div class="row">
              <div class="col-12">
                <h5 class="text-center">ACM Multimedia 2022</h5>
                <h2 class="text-center">Action-conditioned On-demand Motion Generation</h1>
                <p class="text-center">&nbsp;</p>
                <h6 class="text-center"><a href="https://www.linkedin.com/in/qiujing-lu-309042126/">Qiujing Lu</a>, <a href="https://www.linkedin.com/in/zyp5511/">Yipeng Zhang</a>, <a href="https://www.linkedin.com/in/mingjian-lu-357182102/">Mingjian Lu</a>, <a href="http://www.vwaniroychowdhury.com/">Vwani Roychowdhury</a></h6>
                <p class="text-center">Roychowdhury Group @ University of California, Los Angeles</p>
                <hr>
                <p class="text-center" style="font-size:20px">
                <a href="https://github.com/roychowdhuryresearch/ODMO">[Code]</a>
                <a href="https://arxiv.org/abs/2207.08164">[Arxiv]</a>
                <a href="./assets/ODMO_supplementary_document.pdf">[Supp.]</a>
                </p>
              </div>
            </div>
          </div>
        </div>
      </header>
      <section>
        <div class="container">
          <p>&nbsp;</p>
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
              <h2>Abstract</h2>
            </div>
          </div>
        </div>
        <div class="container ">
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-1 col-xl-10"> 
              <p class="text-left"><em>We propose a novel framework, On-Demand MOtion Generation (ODMO), for generating realistic and diverse long-term 3D human motion sequences conditioned only on action types with an additional capability of customization. ODMO shows improvements over SOTA approaches on all traditional motion evaluation metrics when evaluated on three public datasets (HumanAct12, UESTC, and MoCap). Furthermore, we provide both qualitative evaluations and quantitative metrics demonstrating several first-known customization capabilities afforded by our framework, including: (i) ability to discover different modes/styles of motion within each action type in the training set, and then generating samples from these modes on demand; (ii) ability to interpolate between pairs of specified modes (hence, on demand) within an action type to generate diverse motions not seen in the training set; and (iii) ability to customize trajectories and specify destinations of generated motion sequences. These capabilities significantly widen the spectrum of potential applications of such motion generation models. The novel on-demand generative capabilities are enabled by innovations in both the encoder and decoder architectures: (i) Encoder: Utilizing contrastive learning in low-dimensional latent space to create a hierarchical embedding of motion sequences, where not only the codes of different action types form different groups, but within an action type, codes of similar inherent patterns (motion styles) cluster together, making them readily discoverable; (ii) Decoder: Using a hierarchical decoding strategy where the motion trajectory is reconstructed first and then used to reconstruct the whole motion sequence. Such an architecture enables effective trajectory control. </em></p>
              <p class="text-left">&nbsp;</p>
              <p class="text-left">&nbsp;</p>
              <img src="assets/acmmm_mesh.png" width="100%" alt=""/>
              <p>Fig 1. : On-Demand MOtion Generation(ODMO) can generate diverse and realistic 3D human motion sequences conditioned
                on action type ùëê with the capability of automated discovery and controllable generation of different subtypes in a given category.</p>
              <p>&nbsp;</p>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-1 col-xl-10"> 
            <img src="assets/architecture.png" width="100%" alt="" class="rounded mx-auto d-block"/>
              <p>&nbsp;</p>
              <p class="text-center">Fig 2. ODMO model architecture.</p>
              <p>&nbsp;</p>
              <p>&nbsp;</p>
            </div>
          </div>
          <!-- <hr>
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
              <h2>Results </h2>
              <p>&nbsp;</p>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-1 col-xl-10"> <img src="assets/results.jpg" width="800" alt=""/>
              <p>&nbsp;</p>
              <p class="text-center">Fig 3. Single-image reconstruction results using our FaceVerse model.</p>
              <p>&nbsp;</p>
            </div>
            <div class="col-lg-12 col-md-12 col-sm-12 text-center offset-xl-1 col-xl-10"> <img src="assets/tracking_v2.gif" width="500" alt=""/>
              <p>&nbsp;</p>
              <p class="text-center">Fig 4. Real-time face tracking and model driving using a single RGB camera with our FaceVerse base model.</p>
              <p>&nbsp;</p>
            </div>
          </div> -->
          <hr>
          <div class="row">
            <div class="col-lg-12 mb-4 mt-2 text-center">
              <h2>Supplementary Video</h2>
            </div>
          </div>
          <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
            <video controls="controls" width="80%">
              <source src="./assets/ODMO_supplementary_video.mp4" type="video/mp4">
            </video>
            <p>&nbsp;</p>
          </div>
        <hr>
          <div class="row">
            <div class="col-lg-12 mb-4 mt-2 text-center">
              <h2>Talk Video</h2>
            </div>
          </div>
          <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
            <video controls="controls" width="80%">
              <source src="./assets/Talk.mp4" type="video/mp4">
            </video>
            <p>&nbsp;</p>
          </div>
        <!-- <hr>
          <div class="row">
            <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-center">
              <h2>Citation</h2>
            </div>
          </div>
          <div class="col-lg-12 col-md-12 col-sm-12 col-xl-12 text-left">
            <p><span style="color:#000000;font-family:'Courier New';font-size:15px;"> Lizhen Wang, Zhiyuan Chen, Tao Yu, Chenguang Ma, Liang Li, and Yebin Liu. "FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset". IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</span></p>
            <p>&nbsp;</p>
            <p><span style="color:#000000;font-family:'Courier New';font-size:15px;">@inproceedings{wang2022faceverse, <br>
            title={FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset},<br>
            author={Wang, Lizhen and Chen, Zhiyua and Yu, Tao and Ma, Chenguang and Li, Liang and Liu, Yebin},<br>
            booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR2022)},<br>
            month={June},<br>
            year={2022}<br>
          }</span></p> -->
            <p>&nbsp;</p>
            <p>&nbsp;</p>
          </div>
          <div class="row"> </div>
        </div>
        <div class="jumbotron"> </div>
      </section>	
      </div>


    <script src="./js/jquery-3.2.1.slim.min.js"></script>
    <script src="./js/popper.min.js"></script>
    <script src="./js/bootstrap.min.js"></script>  
  </body>
</html>